# Automatic Diagnosis of Prostate Cancer in Histopathological Images

This repository contains the source code and experimental framework for the Master's thesis titled "Automatic Diagnosis of prostate cancer in histopathological images," authored by Damian Tworek at the AGH University of Science and Technology.

The project focuses on developing deep learning models for classifying prostate cancer in histopathological images and, more importantly, critically evaluating the transparency and consistency of these models using Explainable AI (XAI) techniques.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Table of Contents
- [Abstract](#abstract)
- [Key Features](#key-features)
- [Repository Structure](#repository-structure)
- [Setup and Installation](#setup-and-installation)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Dataset](#dataset)
- [Usage and Workflow](#usage-and-workflow)
  - [1. Training the Models](#1-training-the-models)
  - [2. Testing and Evaluating Models](#2-testing-and-evaluating-models)
  - [3. Explainability (XAI) Analysis](#3-explainability-xai-analysis)
- [Scripts Overview](#scripts-overview)
- [How to Cite](#how-to-cite)

## Abstract
The integration of deep learning with digital histopathology holds significant potential to advance the automated diagnosis of prostate cancer. However, the inherent "black-box" nature of these models is a critical barrier to clinical adoption. This thesis investigates explainable AI (XAI) methods to increase the transparency of Convolutional Neural Networks (CNNs) for prostate histopathology. We develop and train VGG-16 models on the public **DiagSet** dataset at multiple magnifications (10x, 20x, 40x). We then systematically apply and compare three XAI methods—**Grad-CAM**, **Grad-CAM++**, and **LayerCAM**—across different network layers and magnifications to assess their consistency and reliability. Our findings demonstrate that while models achieve high classification accuracy, the explanations generated by different XAI methods often diverge, and that intermediate network layers can provide more valuable insights than the final layer. This work underscores the critical need for a multi-faceted, quantitative approach to validating AI-driven diagnostic systems.

## Key Features
- **Training Pipeline:** A robust training script (`train.py`) for VGG-16 models on the DiagSet dataset, supporting staged fine-tuning and multi-GPU training.
- **Multi-Magnification Support:** Independent models trained for 10x, 20x, and 40x magnification levels.
- **Explainability (XAI) Framework:** A comprehensive analysis pipeline (`my_template_match.py`) to:
    - Locate specific image patches within a Whole Slide Image (WSI).
    - Extract corresponding patches at higher resolutions.
    - Generate and save heatmaps using Grad-CAM, Grad-CAM++, and LayerCAM.
- **Quantitative Comparison:** A script (`comparison_table.py`) to parse experiment logs and generate SSIM/Cosine Similarity comparison tables and heatmaps, quantifying the agreement between different XAI methods and scales.
- **Metrics and Visualization:** Scripts for plotting training progress (`plot_metrics_from_log_file.py`) and generating ROC/AUC curves (`auc.py`).

## Repository Structure
```
.
├── 10x/                        # Output directory for 10x model training
├── 20x/                        # Output directory for 20x model training
├── 40x/                        # Output directory for 40x model training
├── data/                       # Placeholder for the DiagSet-A.2 dataset
│   └── DiagSet-A.2/
│       ├── blobs/
│       ├── distributions/
│       └── partitions/
├── logs/                       # Log files from patch matching and analysis
├── results/                    # Directory for generated figures and tables
│
├── auc.py                      # Script to run testing and generate ROC/AUC curves
├── comparison_table.py         # Parses logs to create SSIM comparison heatmaps
├── gradcam.py                  # Basic script for generating Grad-CAM on a single file
├── merge_images.py             # Utility to create grid-visualizations of tile sets
├── my_template_match.py        # Core script for patch localization and XAI analysis
├── patch.py                    # Utility to extract individual .png patches from .npy blobs
├── plot_metrics_from_log_file.py # Generates training/validation plots from logs
├── train.py                    # Main training script for the models
├── show_wsi_thumbnail.py       # Helper to display a WSI thumbnail
└── README.md                   # This file
```

## Setup and Installation

### Prerequisites
- Python 3.9+
- A `conda` or `venv` environment is highly recommended.
- Access to a CUDA-enabled GPU for training and inference.

### Installation
1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/your-repository-name.git
   cd your-repository-name
   ```
2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
   ```
3. **Install the required packages:**
   A `requirements.txt` file is provided for convenience.
   ```bash
   pip install -r requirements.txt
   ```
   *(Note: The `requirements.txt` should contain packages like `torch`, `torchvision`, `numpy`, `pandas`, `openslide-python`, `scikit-image`, `scikit-learn`, `matplotlib`, `opencv-python`, `seaborn`, `pytorch-grad-cam`.)*

### Dataset
This project uses the **DiagSet-A.2** dataset. Due to its large size (>350 GB), it is not included in this repository.
1. **Download the Dataset:** Obtain the dataset from the official [DiagSet repository](https://github.com/michalkoziarski/DiagSet) or the data center as specified in the thesis appendix.
2. **Directory Structure:** Unzip and place the dataset in the `data/` directory, following the structure expected by the scripts:
   ```
   data/
   └── DiagSet-A.2/
       ├── blobs/
       ├── distributions/
       └── partitions/
   ```

## Usage and Workflow

The project workflow can be broken down into three main stages: training, testing, and XAI analysis.

### 1. Training the Models
The `train.py` script handles model training. The key parameters are magnification and the fine-tuning schedule. A separate model must be trained for each magnification (10x, 20x, 40x).

**Example command to train the 10x model:**
```bash
python train.py \
    --output_dir 10xnew \
    --root_dir data/DiagSet-A.2 \
    --magnification 10x \
    --batch_size 1024 \
    --epochs 330 \
    --freeze_schedule "[[1,5,1e-6], [17,5,1e-6], [131,2,1e-7]]" 
```
- `--output_dir`: Where to save checkpoints and logs.
- `--magnification`: The target magnification (`10x`, `20x`, or `40x`).
- `--batch_size`: Adjust based on your GPU memory.
- `--freeze_schedule`: A JSON string defining the staged fine-tuning. `[[epoch, num_frozen_layers, learning_rate], ...]`.

### 2. Testing and Evaluating Models
The `auc.py` script is used to load a trained checkpoint and evaluate it on the test set, producing final metrics and a ROC curve plot.

**Example command to test the 10x model (assuming epoch 320 was the best):**
```bash
python auc.py \
    --test \
    --output_dir 10xnew \
    --root_dir data/DiagSet-A.2 \
    --magnification 10x \
    --batch_size 1024 \
    --resume_epoch 320
```
- `--test`: Puts the script in evaluation mode.
- `--resume_epoch`: Specifies which checkpoint to load from the `--output_dir`.

### 3. Explainability (XAI) Analysis
This is a multi-step process orchestrated by the `my_template_match.py` script.

#### 3.1. Locate Patch and Generate XAI Heatmaps
This script finds a specific patch from the dataset within its original WSI, extracts the corresponding regions at all magnifications, and applies Grad-CAM, Grad-CAM++, and LayerCAM across multiple layers.

**Example command:**
```bash
python my_template_match.py \
    --slide_path data/WSI/2315BEF6-3832-4AB9-8F6D-3514AD4E6925.ndpi \
    --target_image_path data/DiagSet-A.2/blobs/S/10x/2315BEF6-3832-4AB9-8F6D-3514AD4E6925/R4 \
    --output_folder results/run_2315BEF6 \
    --model_10x_path 10xnew/checkpoint_epoch_320.pth \
    --model_20x_path 20xnew/checkpoint_epoch_173.pth \
    --model_40x_path 40xnew/checkpoint_epoch_97.pth
```
- The script first displays a thumbnail of the WSI. You must select regions of interest with your mouse to narrow the search space.
- Once a patch is matched, it will create an output folder (e.g., `results/run_2315BEF6_...`) containing the extracted tiles and all generated XAI heatmaps as both `.png` and `.npy` files.
- It also logs the SSIM/cosine similarity comparisons to a log file in the `logs/` directory.

#### 3.2. Analyze XAI Comparison Results
After running the analysis script, use `comparison_table.py` to parse the log file and generate summary heatmaps.

**Example command:**
```bash
python comparison_table.py logs/2315BEF6-3832-4AB9-8F6D-3514AD4E6925.log
```
This will print summary tables to the console and save PNG heatmaps (e.g., `heatmap_ssim_GradCAM_vs_GradCAM++.png`) to your root directory, visualizing the agreement between different XAI methods.

## Scripts Overview

- **`train.py`**: The main script for training VGG-16 models with staged fine-tuning.
- **`auc.py`**: A modification of `train.py` to specifically run evaluation on the test set and generate ROC/AUC curves and associated metrics.
- **`my_template_match.py`**: The core analysis script. It performs patch localization within WSIs, extracts multi-resolution tiles, and generates/compares XAI heatmaps for a comprehensive analysis.
- **`comparison_table.py`**: A post-processing script that reads log files from `my_template_match.py` to create quantitative comparison tables and visualizations (heatmaps) of XAI method agreement.
- **`plot_metrics_from_log_file.py`**: A utility to parse a `training.log` file and plot the learning curves (loss and accuracy over epochs).
- **`gradcam.py` / `merge_images.py` / `merge_gradcams.py`**: Helper and experimental scripts for visualizing and combining CAM outputs.
- **`patch.py`**: A utility to unpack `.npy` patch blobs into individual `.png` files for easy inspection.
- **`show_wsi_thumbnail.py`**: A simple utility to display a thumbnail of a given WSI file.

## How to Cite

If you use this code or reference the findings from the thesis in your research, please cite the original work:

```bibtex
@mastersthesis{Tworek2025,
  author  = {Damian Tworek},
  title   = {Automatic Diagnosis of prostate cancer in histopathological images},
  school  = {AGH University of Science and Technology, Faculty of Computer Science},
  year    = {2025},
  address = {Kraków, Poland},
}
```
